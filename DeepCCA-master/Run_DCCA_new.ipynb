{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "from linear_cca import linear_cca\n",
    "from torch.utils.data import BatchSampler, SequentialSampler, Dataset\n",
    "from DeepCCAModels import DeepCCA\n",
    "from main import Solver\n",
    "from utils import load_data, svm_classify\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import cPickle as thepickle\n",
    "except ImportError:\n",
    "    import _pickle as thepickle\n",
    "\n",
    "import gzip\n",
    "import numpy as np\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "from multiview.embed.gcca import GCCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "np.set_printoptions(suppress=True) # don't use scientific [e.g. 5e10] notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 0 GPUs\n"
     ]
    }
   ],
   "source": [
    "# Parameters Section\n",
    "device = torch.device('cpu')\n",
    "print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n",
    "\n",
    "# the path to save the final learned features\n",
    "save_to = './new_features.gz'\n",
    "\n",
    "# the size of the new space learned by the model (number of the new features)\n",
    "outdim_size = 50\n",
    "\n",
    "# size of the input for view 1 and view 2\n",
    "input_shape1 = 392\n",
    "input_shape2 = 392\n",
    "\n",
    "# number of layers with nodes in each one\n",
    "# layer_sizes1 = [1024, 1024, 1024, outdim_size]\n",
    "# layer_sizes2 = [1024, 1024, 1024, outdim_size]\n",
    "layer_sizes1 = [2038, outdim_size]\n",
    "layer_sizes2 = [1608, outdim_size]\n",
    "\n",
    "# the parameters for training the network\n",
    "learning_rate = 1e-3\n",
    "epoch_num = 10\n",
    "batch_size = 800\n",
    "\n",
    "# the regularization parameter of the network\n",
    "# seems necessary to avoid the gradient exploding especially when non-saturating activations are used\n",
    "reg_par = 1e-5\n",
    "\n",
    "# specifies if all the singular values should get used to calculate the correlation or just the top outdim_size ones\n",
    "# if one option does not work for a network or dataset, try the other one\n",
    "use_all_singular_values = False\n",
    "\n",
    "# if a linear CCA should get applied on the learned features extracted from the networks\n",
    "# it does not affect the performance on noisy MNIST significantly\n",
    "apply_linear_cca = True\n",
    "# end of parameters section\n",
    "############\n",
    "\n",
    "### Don't need this right now since not using noisy mnist\n",
    "# Each view is stored in a gzip file separately. They will get downloaded the first time the code gets executed.\n",
    "# Datasets get stored under the datasets folder of user's Keras folder\n",
    "# normally under [Home Folder]/.keras/datasets/\n",
    "# data1 = load_data('./noisymnist_view1.gz')\n",
    "# data2 = load_data('./noisymnist_view2.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_left_right():\n",
    "    mnist_train = Dataset.mnistDataset = datasets.MNIST(\"./mnist\", train=True, download=True)\n",
    "    mnist_test = datasets.MNIST(\"./mnist/\", train=False, download=True)\n",
    "\n",
    "    data1 = []\n",
    "    data2 = []\n",
    "\n",
    "    #### get train data\n",
    "    temp_array1 = np.zeros((50000, 14*28))\n",
    "    temp_array2 = np.zeros((50000, 14*28))\n",
    "    labels = []\n",
    "    for i in range(len(mnist_train)-10000): # \n",
    "        img, label = mnist_train[i]\n",
    "        labels.append(label)\n",
    "        img = np.array(img) / 255\n",
    "        image1, image2 = img[:,:14], img[:,14:]\n",
    "        temp_array1[i,:] = np.reshape(image1, (1,14*28))\n",
    "        temp_array2[i,:] = np.reshape(image2, (1,14*28))\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    temp_array1 = torch.tensor(temp_array1)\n",
    "    temp_array2 = torch.tensor(temp_array2)\n",
    "    data1.append((temp_array1, labels))\n",
    "    data2.append((temp_array2, labels))\n",
    "    #### get eval data\n",
    "    temp_array1 = np.zeros((10000, 14*28))\n",
    "    temp_array2 = np.zeros((10000, 14*28))\n",
    "    labels = []\n",
    "    for i in range(10000): # \n",
    "        img, label = mnist_train[i+50000]\n",
    "        labels.append(label)\n",
    "        img = np.array(img) / 255\n",
    "        image1, image2 = img[:,:14], img[:,14:]\n",
    "        temp_array1[i,:] = np.reshape(image1, (1,14*28))\n",
    "        temp_array2[i,:] = np.reshape(image2, (1,14*28))\n",
    "    labels = np.array(labels)\n",
    "    temp_array1 = torch.tensor(temp_array1)\n",
    "    temp_array2 = torch.tensor(temp_array2)\n",
    "    data1.append((temp_array1, labels))\n",
    "    data2.append((temp_array2, labels))\n",
    "    #### get test data\n",
    "    temp_array1 = np.zeros((10000, 14*28))\n",
    "    temp_array2 = np.zeros((10000, 14*28))\n",
    "    labels = []\n",
    "    for i in range(10000): # \n",
    "        img, label = mnist_test[i]\n",
    "        labels.append(label)\n",
    "        img = np.array(img) / 255\n",
    "        image1, image2 = img[:,:14], img[:,14:]\n",
    "        temp_array1[i,:] = np.reshape(image1, (1,14*28))\n",
    "        temp_array2[i,:] = np.reshape(image2, (1,14*28))\n",
    "    labels = np.array(labels)\n",
    "    temp_array1 = torch.tensor(temp_array1)\n",
    "    temp_array2 = torch.tensor(temp_array2)\n",
    "    data1.append((temp_array1, labels))\n",
    "    data2.append((temp_array2, labels))\n",
    "    return data1, data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitMNIST(Dataset):\n",
    "  \"\"\"\n",
    "  Returns 2 views of the MNIST dataset. View 1 is the left half of each image,\n",
    "  and View 2 is the right half.\n",
    "  \"\"\"\n",
    "  def __init__(self, train=True):\n",
    "    super().__init__()\n",
    "    self.mnistDataset = datasets.MNIST(\"./mnist\", train=train, download=True)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.mnistDataset)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    randomIndex = lambda: np.random.randint(len(self.mnistDataset))\n",
    "    image1, label1 = self.mnistDataset[idx]\n",
    "\n",
    "    image1 = np.array(image1) / 255\n",
    "    image1, image2 = image1[:,:14], image1[:,14:]\n",
    "\n",
    "\n",
    "    image1 = torch.FloatTensor(image1).unsqueeze(0)\n",
    "    image2 = torch.FloatTensor(image2).unsqueeze(0)\n",
    "\n",
    "    return (image1, image2, label1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1, data2 = mnist_left_right()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ INFO : 2020-02-11 10:36:39,382 ] - DataParallel(\n",
      "  (module): DeepCCA(\n",
      "    (model1): MlpNet(\n",
      "      (layers): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Linear(in_features=392, out_features=2038, bias=True)\n",
      "          (1): Sigmoid()\n",
      "        )\n",
      "        (1): Linear(in_features=2038, out_features=50, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (model2): MlpNet(\n",
      "      (layers): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Linear(in_features=392, out_features=1608, bias=True)\n",
      "          (1): Sigmoid()\n",
      "        )\n",
      "        (1): Linear(in_features=1608, out_features=50, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[ INFO : 2020-02-11 10:36:39,383 ] - RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    momentum: 0\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "[ INFO : 2020-02-11 10:36:45,579 ] - Epoch 1: val_loss improved from 0.0000 to -25.7335, saving model to checkpoint.model\n",
      "[ INFO : 2020-02-11 10:36:45,586 ] - Epoch 1/10 - time: 6.20 - training_loss: -23.0980 - val_loss: -25.7335\n",
      "[ INFO : 2020-02-11 10:36:52,525 ] - Epoch 2: val_loss improved from -25.7335 to -29.1035, saving model to checkpoint.model\n",
      "[ INFO : 2020-02-11 10:36:52,531 ] - Epoch 2/10 - time: 6.94 - training_loss: -25.2196 - val_loss: -29.1035\n",
      "[ INFO : 2020-02-11 10:36:59,388 ] - Epoch 3: val_loss improved from -29.1035 to -32.2982, saving model to checkpoint.model\n",
      "[ INFO : 2020-02-11 10:36:59,393 ] - Epoch 3/10 - time: 6.86 - training_loss: -27.1785 - val_loss: -32.2982\n",
      "[ INFO : 2020-02-11 10:37:06,144 ] - Epoch 4: val_loss improved from -32.2982 to -34.8677, saving model to checkpoint.model\n",
      "[ INFO : 2020-02-11 10:37:06,150 ] - Epoch 4/10 - time: 6.76 - training_loss: -28.9646 - val_loss: -34.8677\n",
      "[ INFO : 2020-02-11 10:37:12,823 ] - Epoch 5: val_loss improved from -34.8677 to -36.7884, saving model to checkpoint.model\n",
      "[ INFO : 2020-02-11 10:37:12,828 ] - Epoch 5/10 - time: 6.68 - training_loss: -30.5172 - val_loss: -36.7884\n",
      "[ INFO : 2020-02-11 10:37:19,659 ] - Epoch 6: val_loss improved from -36.7884 to -38.1541, saving model to checkpoint.model\n",
      "[ INFO : 2020-02-11 10:37:19,665 ] - Epoch 6/10 - time: 6.84 - training_loss: -31.8394 - val_loss: -38.1541\n",
      "[ INFO : 2020-02-11 10:37:26,569 ] - Epoch 7: val_loss improved from -38.1541 to -39.0794, saving model to checkpoint.model\n",
      "[ INFO : 2020-02-11 10:37:26,574 ] - Epoch 7/10 - time: 6.91 - training_loss: -32.9459 - val_loss: -39.0794\n",
      "[ INFO : 2020-02-11 10:37:33,579 ] - Epoch 8: val_loss improved from -39.0794 to -39.8364, saving model to checkpoint.model\n",
      "[ INFO : 2020-02-11 10:37:33,585 ] - Epoch 8/10 - time: 7.01 - training_loss: -33.8799 - val_loss: -39.8364\n",
      "[ INFO : 2020-02-11 10:37:40,571 ] - Epoch 9: val_loss improved from -39.8364 to -40.3738, saving model to checkpoint.model\n",
      "[ INFO : 2020-02-11 10:37:40,576 ] - Epoch 9/10 - time: 6.99 - training_loss: -34.6765 - val_loss: -40.3738\n",
      "[ INFO : 2020-02-11 10:37:47,718 ] - Epoch 10: val_loss improved from -40.3738 to -40.9072, saving model to checkpoint.model\n",
      "[ INFO : 2020-02-11 10:37:47,724 ] - Epoch 10/10 - time: 7.15 - training_loss: -35.3709 - val_loss: -40.9072\n",
      "[ INFO : 2020-02-11 10:37:50,489 ] - loss on validation data: -40.9072\n",
      "[ INFO : 2020-02-11 10:37:50,936 ] - loss on test data: -40.3025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear CCA started!\n"
     ]
    }
   ],
   "source": [
    "# Building, training, and producing the new features by DCCA\n",
    "model = DeepCCA(layer_sizes1, layer_sizes2, input_shape1,\n",
    "                input_shape2, outdim_size, use_all_singular_values, device=device).double()\n",
    "l_cca = None\n",
    "if apply_linear_cca:\n",
    "    l_cca = linear_cca()\n",
    "solver = Solver(model, l_cca, outdim_size, epoch_num, batch_size,\n",
    "                learning_rate, reg_par, device=device)\n",
    "train1, train2 = data1[0][0], data2[0][0]\n",
    "val1, val2 = data1[1][0], data2[1][0]\n",
    "test1, test2 = data1[2][0], data2[2][0]\n",
    "# val1=None\n",
    "# test1=None\n",
    "solver.fit(train1, train2, val1, val2, test1, test2)\n",
    "# TODO: Save linear_cca model if needed\n",
    "\n",
    "set_size = [0, train1.size(0), train1.size(\n",
    "    0) + val1.size(0), train1.size(0) + val1.size(0) + test1.size(0)]\n",
    "loss, outputs = solver.test(torch.cat([train1, val1, test1], dim=0), torch.cat(\n",
    "    [train2, val2, test2], dim=0), apply_linear_cca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-View Correlations before and after transformation\n",
      "Train: [3.18240939] -> [42.15251606]\n",
      "Test: [3.17578552] -> [41.28774998]\n"
     ]
    }
   ],
   "source": [
    "### Compute correlations between 50 features\n",
    "new_data = []\n",
    "# print(outputs)\n",
    "for idx in range(3):\n",
    "    new_data.append([outputs[0][set_size[idx]:set_size[idx + 1], :],\n",
    "                     outputs[1][set_size[idx]:set_size[idx + 1], :], data1[idx][1]])\n",
    "\n",
    "X1_train, X2_train, train_label = new_data[0]\n",
    "X1_val, X2_val, valid_label = new_data[1]\n",
    "X1_test, X2_test, test_label = new_data[2]\n",
    "\n",
    "sum_corr_train = 0\n",
    "for idx, (row1, row2) in enumerate(zip(X1_train, X2_train)):\n",
    "    sum_corr_train += np.correlate(row1, row2)\n",
    "    \n",
    "corr_train = sum_corr_train/idx\n",
    "    \n",
    "sum_corr_test = 0\n",
    "for idx, (row1, row2) in enumerate(zip(X1_test, X2_test)):\n",
    "    sum_corr_test += np.correlate(row1, row2)\n",
    "    \n",
    "corr_test = sum_corr_test/idx\n",
    "    \n",
    "\n",
    "### Compute correlations of original images\n",
    "X1_train, _ = data1[0]\n",
    "X2_train, _ = data2[0]\n",
    "X1_val, _ = data1[1]\n",
    "X2_val, _ = data2[1]\n",
    "X1_test, _ = data1[2]\n",
    "X2_test, _ = data2[2]\n",
    "\n",
    "X1_train = X1_train.numpy()\n",
    "X2_train = X2_train.numpy()\n",
    "X1_val = X1_val.numpy()\n",
    "X2_val = X2_val.numpy()\n",
    "X1_test = X1_test.numpy()\n",
    "X2_test = X2_test.numpy()\n",
    "\n",
    "sum_corr_train_orig = 0\n",
    "for idx, (row1, row2) in enumerate(zip(X1_train, X2_train)):\n",
    "    sum_corr_train_orig += np.correlate(row1, row2)\n",
    "corr_train_orig = sum_corr_train_orig/idx    \n",
    "\n",
    "sum_corr_test_orig = 0\n",
    "for idx, (row1, row2) in enumerate(zip(X1_test, X2_test)):\n",
    "    sum_corr_test_orig += np.correlate(row1, row2)\n",
    "corr_test_orig = sum_corr_test_orig/idx\n",
    "\n",
    "print(\"Cross-View Correlations before and after transformation\")\n",
    "print(\"Train: {} -> {}\".format(corr_train_orig, corr_train))\n",
    "print(\"Test: {} -> {}\".format(corr_test_orig, corr_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49998, 392)\n",
      "(10000, 392)\n"
     ]
    }
   ],
   "source": [
    "# remove the examples that are all 0's so that GCCA can work\n",
    "    \n",
    "bad_rows = []\n",
    "for idx, (row1, row2) in enumerate(zip(X1_train, X2_train)):\n",
    "    if (not row1.any()) or (not row2.any()):  # one of the rows has only 0's\n",
    "        bad_rows.append(idx)\n",
    "        \n",
    "X1_train_filtered = np.delete(X1_train, bad_rows, axis=0)\n",
    "X2_train_filtered = np.delete(X2_train, bad_rows, axis=0)\n",
    "print(X2_train_filtered.shape)\n",
    "\n",
    "bad_rows = []\n",
    "for idx, (row1, row2) in enumerate(zip(X1_test, X2_test)):\n",
    "    if (not row1.any()) or (not row2.any()):  # one of the rows has only 0's\n",
    "        bad_rows.append(idx)\n",
    "        \n",
    "X1_test_filtered = np.delete(X1_test, bad_rows, axis=0)\n",
    "X2_test_filtered = np.delete(X2_test, bad_rows, axis=0)\n",
    "print(X2_test_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform GCCA\n",
    "gcca = GCCA(n_components=50)\n",
    "Xs_train = [X1_train_filtered, X2_train_filtered]\n",
    "Xs_test = [X1_test_filtered, X2_test_filtered]\n",
    "latent_train1, latent_train2 = gcca.fit_transform(Xs_train)\n",
    "latent_test1, latent_test2 = gcca.transform(Xs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-View Correlations From GCCA\n",
      "Train: [16.03364892]\n",
      "Test: [15.61656102]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# Compute GCCA correlations\n",
    "sum_corr_train = 0\n",
    "for idx, (row1, row2) in enumerate(zip(latent_train1, latent_train2)):\n",
    "    sum_corr_train += np.correlate(row1, row2)\n",
    "    corr_train = sum_corr_train/idx    \n",
    "\n",
    "sum_corr_test = 0\n",
    "for idx, (row1, row2) in enumerate(zip(latent_test1, latent_test2)):\n",
    "    sum_corr_test += np.correlate(row1, row2)\n",
    "    corr_test = sum_corr_test/idx\n",
    "\n",
    "\n",
    "print(\"Cross-View Correlations From GCCA\")\n",
    "print(\"Train: {}\".format(corr_train))\n",
    "print(\"Test: {}\".format(corr_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
