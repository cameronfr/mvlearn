{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Co-Training Classifier for 2-View Semi-Supervised Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from mvlearn.cotraining.ctclassifier import CTClassifier\n",
    "from mvlearn.datasets.base import load_UCImultifeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the UCI Multiple Digit Features Dataset as an Example for Semi-Supervised Learning\n",
    "To simulate a semi-supervised learning scenario, randomly remove 98% of the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining labeled sample labels: [0. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "data, labels = load_UCImultifeature(select_labeled=[0,1])\n",
    "\n",
    "# Use only the first 2 views as an example\n",
    "View0, View1 = data[0], data[1]\n",
    "\n",
    "# Split both views into testing and training\n",
    "View0_train, View0_test, labels_train, labels_test = train_test_split(View0, labels, test_size=0.33, random_state=42)\n",
    "View1_train, View1_test, labels_train, labels_test = train_test_split(View1, labels, test_size=0.33, random_state=42)\n",
    "\n",
    "# Randomly remove all but 4 of the labels\n",
    "np.random.seed(6)\n",
    "remove_idx = np.random.rand(len(labels_train),) < 0.98\n",
    "labels_train[remove_idx] = np.nan\n",
    "not_removed = np.where(remove_idx==False)\n",
    "print(\"Remaining labeled sample labels: \" + str(labels_train[not_removed]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-Training on 2 Views vs. Single View Semi-Supervised Learning\n",
    "Here, we use the default co-training classifier, which uses Gaussian naive bayes classifiers for both views. We compare its performance to the single-view semi-supervised setting with the same basic classifiers, and with the naive technique of concatenating the two views and performing single view learning.\n",
    "\n",
    "In this case, concatenating the two views does not improve the performance over the better view. Multiview cotraining using the mvlearn package outperforms them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single View Accuracy on First View: 0.803\n",
      "\n",
      "Single View Accuracy on Second View: 0.864\n",
      "\n",
      "Naive Concatenated View Accuracy: 0.864\n",
      "\n",
      "mvlearn Co-Training Accuracy on 2 Views: 0.970\n"
     ]
    }
   ],
   "source": [
    "############## Single view semi-supervised learning ##############\n",
    "#-----------------------------------------------------------------\n",
    "gnb0 = GaussianNB()\n",
    "gnb1 = GaussianNB()\n",
    "gnb2 = GaussianNB()\n",
    "\n",
    "# Train on only the examples with labels\n",
    "gnb0.fit(View0_train[not_removed,:].squeeze(), labels_train[not_removed])\n",
    "y_pred0 = gnb0.predict(View0_test)\n",
    "gnb1.fit(View1_train[not_removed,:].squeeze(), labels_train[not_removed])\n",
    "y_pred1 = gnb1.predict(View1_test)\n",
    "# Concatenate the 2 views for naive \"multiview\" learning\n",
    "View01_train = np.hstack((View0_train[not_removed,:].squeeze(), View1_train[not_removed,:].squeeze()))\n",
    "View01_test = np.hstack((View0_test, View1_test))\n",
    "gnb2.fit(View01_train, labels_train[not_removed])\n",
    "y_pred2 = gnb2.predict(View01_test)\n",
    "\n",
    "print(\"Single View Accuracy on First View: {0:.3f}\\n\".format(accuracy_score(labels_test, y_pred0)))\n",
    "print(\"Single View Accuracy on Second View: {0:.3f}\\n\".format(accuracy_score(labels_test, y_pred1)))\n",
    "print(\"Naive Concatenated View Accuracy: {0:.3f}\\n\".format(accuracy_score(labels_test, y_pred2)))\n",
    "\n",
    "\n",
    "######### Multi-view co-training semi-supervised learning #########\n",
    "#------------------------------------------------------------------\n",
    "# Train a CTClassifier on all the labeled and unlabeled training data\n",
    "ctc = CTClassifier()\n",
    "ctc.fit([View0_train, View1_train], labels_train)\n",
    "y_pred_ct = ctc.predict([View0_test, View1_test])\n",
    "\n",
    "print(\"mvlearn Co-Training Accuracy on 2 Views: {0:.3f}\".format(accuracy_score(labels_test, y_pred_ct)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Different Base Classifiers for the Views and Change the CTClassifier fit() parameters\n",
    "Now, we use a random forest classifier with different attributes for each view. \n",
    "Furthermore, we manually select the number of positive (p) and negative (n) examples chosen each round in the co-training process, and we define the unlabeled pool size to draw them from and the number of iterations of training to perform.\n",
    "\n",
    "In this case, concatenating the two views outperforms single view methods, but mvlearn cotraining still performs the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single View Accuracy on First View: 0.932\n",
      "\n",
      "Single View Accuracy on Second View: 0.818\n",
      "\n",
      "Naive Concatenated View Accuracy: 0.985\n",
      "\n",
      "mvlearn Co-Training Accuracy: 0.992\n"
     ]
    }
   ],
   "source": [
    "############## Single view semi-supervised learning ##############\n",
    "#-----------------------------------------------------------------\n",
    "rfc0 = RandomForestClassifier(n_estimators=100, bootstrap=True)\n",
    "rfc1 = RandomForestClassifier(n_estimators=6, bootstrap=False)\n",
    "rfc2 = RandomForestClassifier(n_estimators=100, bootstrap=False)\n",
    "\n",
    "# Train on only the examples with labels\n",
    "rfc0.fit(View0_train[not_removed,:].squeeze(), labels_train[not_removed])\n",
    "y_pred0 = rfc0.predict(View0_test)\n",
    "rfc1.fit(View1_train[not_removed,:].squeeze(), labels_train[not_removed])\n",
    "y_pred1 = rfc1.predict(View1_test)\n",
    "# Concatenate the 2 views for naive \"multiview\" learning\n",
    "View01_train = np.hstack((View0_train[not_removed,:].squeeze(), View1_train[not_removed,:].squeeze()))\n",
    "View01_test = np.hstack((View0_test, View1_test))\n",
    "rfc2.fit(View01_train, labels_train[not_removed])\n",
    "y_pred2 = rfc2.predict(View01_test)\n",
    "\n",
    "print(\"Single View Accuracy on First View: {0:.3f}\\n\".format(accuracy_score(labels_test, y_pred0)))\n",
    "print(\"Single View Accuracy on Second View: {0:.3f}\\n\".format(accuracy_score(labels_test, y_pred1)))\n",
    "print(\"Naive Concatenated View Accuracy: {0:.3f}\\n\".format(accuracy_score(labels_test, y_pred2)))\n",
    "\n",
    "######### mvlearn co-training semi-supervised learning #########\n",
    "#------------------------------------------------------------------\n",
    "rfc0 = RandomForestClassifier(n_estimators=100, bootstrap=True)\n",
    "rfc1 = RandomForestClassifier(n_estimators=6, bootstrap=False)\n",
    "ctc = CTClassifier(rfc0, rfc1, p=2, n=2, unlabeled_pool_size=20, num_iter=100)\n",
    "ctc.fit([View0_train, View1_train], labels_train)\n",
    "y_pred_ct = ctc.predict([View0_test, View1_test])\n",
    "\n",
    "print(\"mvlearn Co-Training Accuracy: {0:.3f}\".format(accuracy_score(labels_test, y_pred_ct)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the prediction probabilities for all the examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full y_proba shape = (132, 2)\n",
      "\n",
      "First 10 class probabilities:\n",
      "\n",
      "[[0.08333333 0.91666667]\n",
      " [0.015      0.985     ]\n",
      " [0.91666667 0.08333333]\n",
      " [0.005      0.995     ]\n",
      " [0.995      0.005     ]\n",
      " [0.77666667 0.22333333]\n",
      " [0.26166667 0.73833333]\n",
      " [0.93       0.07      ]\n",
      " [0.01       0.99      ]\n",
      " [0.96       0.04      ]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = ctc.predict_proba([View0_test, View1_test])\n",
    "print(\"Full y_proba shape = \" + str(y_pred_proba.shape))\n",
    "print(\"\\nFirst 10 class probabilities:\\n\")\n",
    "print(y_pred_proba[:10,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
